{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar_data = torchvision.datasets.CIFAR10('data/cifar-10/', train=True, download=True)\n",
    "cifar_testing = torchvision.datasets.CIFAR10('data/cifar-10/', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mat(mat, n, replace=False, return_idxs=False):\n",
    "    \"\"\"Sample `n` random rows from mat.\n",
    "    Returns an array of the rows sampled from the matrix.\n",
    "    Arguments:\n",
    "        mat {np.array} -- A matrix to sample rows from.\n",
    "        n {int} -- The number of rows to sample.\n",
    "    Keyword Arguments:\n",
    "        replace {bool} -- Whether or not to sample with replacement. (default: {False})\n",
    "        return_idxs {bool} -- Whether or not to return the indexes of the selected rows. (default: {False})\n",
    "    Returns:\n",
    "        np.array|tuple -- Returns a matrix containing the sampled rows, or if `return_idxs` is set,\n",
    "            returns a tuple containing the indexes of the selected rows and the sampled matrix.\n",
    "    \"\"\"\n",
    "    col_idxs = np.random.choice(mat.shape[1], n, replace=replace)\n",
    "    sampled = mat[:, col_idxs]\n",
    "    if return_idxs:\n",
    "        return (col_idxs, sampled)\n",
    "    return sampled\n",
    "\n",
    "def sample_mat_row(mat, n, replace=False, return_idxs=False):\n",
    "    \"\"\"Sample `n` random rows from mat.\n",
    "    Returns an array of the rows sampled from the matrix.\n",
    "    Arguments:\n",
    "        mat {np.array} -- A matrix to sample rows from.\n",
    "        n {int} -- The number of rows to sample.\n",
    "    Keyword Arguments:\n",
    "        replace {bool} -- Whether or not to sample with replacement. (default: {False})\n",
    "        return_idxs {bool} -- Whether or not to return the indexes of the selected rows. (default: {False})\n",
    "    Returns:\n",
    "        np.array|tuple -- Returns a matrix containing the sampled rows, or if `return_idxs` is set,\n",
    "            returns a tuple containing the indexes of the selected rows and the sampled matrix.\n",
    "    \"\"\"\n",
    "    col_idxs = np.random.choice(mat.shape[0], n, replace=replace)\n",
    "    sampled = mat[col_idxs, :]\n",
    "    if return_idxs:\n",
    "        return (col_idxs, sampled)\n",
    "    return sampled    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 1, 2],\n",
       "       [5, 1, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing = [[3,1,2],\n",
    "        [4,1,2],\n",
    "        [5,1,2]]\n",
    "testarr = np.array(thing)\n",
    "col_idxs = np.random.choice(testarr.shape[0], 2, replace=False)\n",
    "testarr[[1,2], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD -\n",
    "# Ours - Uc @ predicted sigma @ Vr (theyre going to be just the regular U and V for smaller matrices)\n",
    "# Poormans Uc @ (sampled sigma) @ (Vr)\n",
    "\n",
    "# reconstruction error | X - Xr |\n",
    "# plot with X as percent sampled from U and V\n",
    "# plot another with x as percent of sigma sampled (0 everything after a certain percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorModule(nn.Module):\n",
    "    def __init__(self, num_units=5000, nonlin=F.relu): # why this param list\n",
    "        super(RegressorModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "        self.dense0 = nn.Linear(1024, num_units)\n",
    "        #self.dropout0 = nn.Dropout(0.7)\n",
    "        self.dense1 = nn.Linear(num_units,750)\n",
    "        self.dropout = nn.Dropout(0.7)\n",
    "        self.dense2 = nn.Linear(750, 300)\n",
    "        self.dropout2 = nn.Dropout(0.7)\n",
    "        self.dense3 = nn.Linear(300, 100)\n",
    "        self.output = nn.Linear(100, 32)\n",
    "\n",
    "    def forward (self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        #X = self.dropout0(X)\n",
    "        X = self.nonlin(self.dense1(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.nonlin(self.dense2(X))\n",
    "        X = self.dropout2(X)\n",
    "        X = self.nonlin(self.dense3(X))\n",
    "        X = self.nonlin(self.output(X))\n",
    "        #X = F.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    RegressorModule, # pytorch module\n",
    "    #train_split=None,\n",
    "    criterion = nn.L1Loss, \n",
    "    max_epochs=512,\n",
    "    lr=0.0001,\n",
    "    device='cuda',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'singular_trained.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\derek\\Documents\\AI-20221026T031243Z-001\\AI\\svdtraining\\poormans-svd-cifar.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/derek/Documents/AI-20221026T031243Z-001/AI/svdtraining/poormans-svd-cifar.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m net\u001b[39m.\u001b[39minitialize()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/derek/Documents/AI-20221026T031243Z-001/AI/svdtraining/poormans-svd-cifar.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m net\u001b[39m.\u001b[39;49mload_params(f_params\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msingular_trained.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\derek\\anaconda3\\lib\\site-packages\\skorch\\net.py:2438\u001b[0m, in \u001b[0;36mNeuralNet.load_params\u001b[1;34m(self, f_params, f_optimizer, f_criterion, f_history, checkpoint, **kwargs)\u001b[0m\n\u001b[0;32m   2436\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_is_fitted([attr], msg\u001b[39m=\u001b[39mmsg_init)\n\u001b[0;32m   2437\u001b[0m module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_module(attr, msg\u001b[39m=\u001b[39mmsg_module)\n\u001b[1;32m-> 2438\u001b[0m state_dict \u001b[39m=\u001b[39m _get_state_dict(f_name)\n\u001b[0;32m   2439\u001b[0m module\u001b[39m.\u001b[39mload_state_dict(state_dict)\n",
      "File \u001b[1;32mc:\\Users\\derek\\anaconda3\\lib\\site-packages\\skorch\\net.py:2395\u001b[0m, in \u001b[0;36mNeuralNet.load_params.<locals>._get_state_dict\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m   2393\u001b[0m map_location \u001b[39m=\u001b[39m get_map_location(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m   2394\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_device(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice, map_location)\n\u001b[1;32m-> 2395\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mload(f, map_location\u001b[39m=\u001b[39;49mmap_location)\n",
      "File \u001b[1;32mc:\\Users\\derek\\anaconda3\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\derek\\anaconda3\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\derek\\anaconda3\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'singular_trained.pkl'"
     ]
    }
   ],
   "source": [
    "net.initialize()\n",
    "net.load_params(f_params='models/singular_trained_nodrop.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_mats = []\n",
    "Xr_mats = []\n",
    "for i in range(1000, 6000, 1000):\n",
    "    m = i\n",
    "    n = i\n",
    "\n",
    "    X = np.random.normal(size=(m, n), scale=10)\n",
    "    mat_rows = sample_mat_row(X, int(0.2*m))\n",
    "    mat_cols = sample_mat(X, int(0.2*m))\n",
    "\n",
    "    # SVD\n",
    "    U, S, V = np.linalg.svd(X)\n",
    "    Ur, Sr, Vr = np.linalg.svd(mat_rows)\n",
    "    Uc, Sc, Vc = np.linalg.svd(mat_cols)\n",
    "\n",
    "    for j in range(2, 32, 2): \n",
    "        S_s = S[0:j]  # zero out the rest\n",
    "        Xr_s = (U @ np.diag(S_s) @ V)\n",
    "        Xr = (U @ np.diag(S) @ V)\n",
    "\n",
    "    # SVD -\n",
    "    # Ours - Uc @ predicted sigma @ Vr\n",
    "    # Poormans Uc @ (sampled sigma) @ (Vr)\n",
    "\n",
    "    # reconstruction error | X - Xr |\n",
    "    # plot with X as percent sampled from U and V\n",
    "    # 10 times and make error bar for each percent error (lineplot errorbar)\n",
    "    # plot another with x as percent of sigma sampled (0 everything after a certain percent)\n",
    "\n",
    "    X_mats.append(X)\n",
    "    Xr_mats.append(Xr_s)\n",
    "    print(f'MSE for {m}x{n}: {mean_squared_error(Xr, X)}')\n",
    "    print(f'MAE for {m}x{n}: {mean_absolute_error(Xr, X)}')\n",
    "    print('-----------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poor poor mans vs Real and Our svd vs Real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "real_mats = []\n",
    "poor_mats = []\n",
    "our_mats = []\n",
    "random_mats = []\n",
    "\n",
    "for i in range(10000):\n",
    "    img, label = cifar_testing[i]\n",
    "    g_img = img.convert('LA')\n",
    "    x = list(g_img.getdata(band=0))\n",
    "\n",
    "    \"\"\"REAL\"\"\"\n",
    "    matrix = np.array(x, float)\n",
    "    matrix.shape = (g_img.size[1], g_img.size[0])\n",
    "    #matrix = np.matrix(matrix)\n",
    "\n",
    "    # svd and rank of image\n",
    "    U, sigma, V = np.linalg.svd(matrix) # computes the SVD\n",
    "    real_mats.append(matrix)\n",
    "\n",
    "\n",
    "    \"\"\"POOOOOR\"\"\"\n",
    "    mat_rows = sample_mat_row(matrix, 15)\n",
    "    mat_cols = sample_mat(matrix, 15)\n",
    "    Ur, Sr, Vr = np.linalg.svd(mat_rows)\n",
    "    Uc, Sc, Vc = np.linalg.svd(mat_cols)\n",
    "\n",
    "    cut_sigma = sigma\n",
    "    cut_sigma[10:] = 0\n",
    "\n",
    "    poor = (Uc @ np.diag(cut_sigma) @ Vr)\n",
    "    poor_mats.append(poor)\n",
    "\n",
    "    \"\"\"OURS\"\"\"\n",
    "    flatten = np.reshape(matrix, (1,1024))\n",
    "    flatten = flatten.astype(np.float32)\n",
    "    prediction = net.predict(flatten)\n",
    "\n",
    "    #print(prediction.shape)\n",
    "    #print(flatten.shape)\n",
    "    #print(U.shape)\n",
    "    #print(V.shape)\n",
    "    #print(prediction)\n",
    "    ours = (U @ np.diag(prediction.ravel()) @ V)\n",
    "    our_mats.append(ours)\n",
    "\n",
    "    \"\"\"Random\"\"\"\n",
    "    \"\"\"OURS\"\"\"\n",
    "    \"\"\"mat = np.zeros((32,32))\n",
    "    med = []\n",
    "    for i in range(20):\n",
    "        # rand\n",
    "        mean = []\n",
    "        mat_rows = sample_mat_row(matrix, 15)\n",
    "        mat_cols = sample_mat(matrix, 15)\n",
    "        Ur, Sr, Vr = np.linalg.svd(mat_rows)\n",
    "        Uc, Sc, Vc = np.linalg.svd(mat_cols)\n",
    "        random = (Uc @ np.diag(prediction.ravel()) @ Vr)\n",
    "        med.append(random)\n",
    "\n",
    "    m = np.dstack(med)\n",
    "    random_mats.append(np.median(m, 2))\"\"\"\n",
    "  \n",
    "\n",
    "    random = (Uc @ np.diag(prediction.ravel()) @ Vr)\n",
    "    random_mats.append(random)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#poor_real = np.array(real_svd)\n",
    "#poor_fake = np.array(fake_svd)\n",
    "real = np.array(real_mats)\n",
    "poor = np.array(poor_mats)\n",
    "predicted = np.array(our_mats)\n",
    "rand = np.array(random_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "rand_int = np.random.randint(0, 10000)\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15,20))\n",
    "\n",
    "\"\"\"Use case for using actual image instead of SVD real\"\"\"\n",
    "if True: \n",
    "    img, label = cifar_testing[rand_int]\n",
    "    g_img = img.convert('LA')\n",
    "\n",
    "axs[0].imshow(g_img, cmap='gray')\n",
    "axs[0].set_title('Real')\n",
    "\n",
    "axs[1].imshow(rand[rand_int], cmap='gray')\n",
    "axs[1].set_title('Sampled')\n",
    "\n",
    "axs[2].imshow(predicted[rand_int], cmap='gray')\n",
    "axs[2].set_title('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\"\"\"Poor-mans vs Real error\"\"\"\n",
    "PR_erro = []\n",
    "for i in range(10000):\n",
    "    PR_erro.append(mean_absolute_error(real[i], poor[i]))\n",
    "PR_error = np.array(PR_erro)\n",
    "\n",
    "\"\"\"Real vs Predictions\"\"\"\n",
    "OR_erro = []\n",
    "for i in range(10000):\n",
    "    OR_erro.append(mean_absolute_error(real[i], predicted[i]))\n",
    "OR_error = np.array(OR_erro)\n",
    "\n",
    "RA_erro = []\n",
    "for i in range(10000):\n",
    "    RA_erro.append(mean_absolute_error(real[i], rand[i]))\n",
    "RA_error = np.array(RA_erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# plotting errors\n",
    "\n",
    "#plt.plot(np.array(PR_error), label=\"Poor Error\")\n",
    "plt.plot(np.array(OR_error), label=\"Pred Error\")\n",
    "plt.plot(np.array(RA_error), label=\"Subset SVD\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"AVG ERRORS\"\"\"\n",
    "APR_error = np.mean(PR_error)\n",
    "AOR_error = np.mean(OR_error)\n",
    "print(\"ERRORS\")\n",
    "print(f'POOR-MANS --- MEAN: {APR_error} \\u00B1 {np.std(PR_error)}')\n",
    "print(f'PREDICTED --- MEAN: {AOR_error} \\u00B1 {np.std(OR_error)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "APR_error.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poor poor mans svd. Error vs % of Rols/cols used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# poor poor mans svd, testing to see how Uc, Vr % affects accuracy\n",
    "percents_errors = []\n",
    "min_max = []\n",
    "for i in range(10000):\n",
    "    img, label = cifar_testing[i]\n",
    "    g_img = img.convert('LA')\n",
    "    x = list(g_img.getdata(band=0))\n",
    "\n",
    "    matrix = np.array(x, float)\n",
    "    matrix.shape = (g_img.size[1], g_img.size[0])\n",
    "    #matrix = np.matrix(matrix)\n",
    "\n",
    "    # svd and rank of image\n",
    "    U, sigma, V = np.linalg.svd(matrix) # computes the SVD\n",
    "    \n",
    "\n",
    "    for j in range(2,32,2):\n",
    "        mat_rows = sample_mat_row(matrix, j)\n",
    "        mat_cols = sample_mat(matrix, j)\n",
    "        Ur, Sr, Vr = np.linalg.svd(mat_rows)\n",
    "        Uc, Sc, Vc = np.linalg.svd(mat_cols)\n",
    "        Xr_s = (Uc @ np.diag(sigma) @ Vr)\n",
    "        Xr = (U @ np.diag(sigma) @ V)\n",
    "        percents_errors.append(mean_absolute_error(Xr_s, Xr))\n",
    "        min_max.append([np.max(Xr), np.min(Xr_s)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "errors = np.array(percents_errors)\n",
    "minmax = np.array(min_max)\n",
    "\n",
    "errors = errors.reshape(-1, 15)\n",
    "errors.shape\n",
    "errors_means = np.mean(errors, axis=0)\n",
    "\n",
    "plt.semilogy(np.arange(2,32,2)/32,errors_means)#.set_title('MAE vs. Number of Rows/cols used (counted in 2)')\n",
    "plt.title('SemilogY Error vs % Rows/Cols')\n",
    "# x axis is number of rows/cols used out of the original 32. This counts by 2 (15 is 30 rows/cols). How to make x-axis go by percentage of 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# only end, theres huge spike that the true X doesnt reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.7 64-bit (microsoft store)' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/derek/AppData/Local/Microsoft/WindowsApps/python3.10.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# how to train the model for each 1000-1000 - 5000 for sigma (we prob dont have to since we're just testing whether\n",
    "# poor mans svd works)\n",
    "# Are the matrices of both poor-mans and regular svd constructed to become the same size? (both same nxn)\n",
    "# can't get it to save as a 3x1000x1000 and only as a 3xobjects\n",
    "\n",
    "# can neural nets take in different sizes than they were trained with"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "951182d8dbb58b547fdeca05ad30e9ec800736ed3bac05ccd98e7b6f2e59da18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
